{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install -U albumentations\n",
    "!pip install lpips\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import autograd\n",
    "from torchvision.models import vgg19, VGG19_Weights\n",
    "import lpips\n",
    "from torchvision import transforms\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "from enum import Enum\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import sys\n",
    "Device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.cuda.init()"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "6224f19c82f368d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class convelutional_block(nn.Module):\n",
    "    def __init__(self, in_channels = 3, out_channels = 64,kernel_size = 9 ,padding = 4, stride = 1):\n",
    "        super(convelutional_block, self).__init__()\n",
    "        self.convo1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.PR = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.convo1(x)\n",
    "        x = self.PR(x)\n",
    "        return x\n",
    "\n",
    "class Resedual_connection(nn.Module):\n",
    "    def __init__(self,kernel_size = 3,channels = 64,padding = 1, stride = 1):\n",
    "        super(Resedual_connection, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(channels, channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm2d(channels)\n",
    "        self.prelu = nn.PReLU()\n",
    "        self.conv2 = nn.Conv2d(channels, channels, kernel_size,stride, padding)\n",
    "        self.bn2 = nn.BatchNorm2d(channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.prelu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += residual\n",
    "        return x\n",
    "\n",
    "class Post_residual_convolution(nn.Module):\n",
    "    def __init__(self, in_channels = 64,  kernel_size = 3, padding = 1, stride = 1):\n",
    "        super(Post_residual_convolution, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, in_channels, kernel_size, stride, padding)\n",
    "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        return x\n",
    "\n",
    "class Upsample_block(nn.Module):\n",
    "    def __init__(self, in_channels = 64, out_channels = 256, kernel_size = 3, padding = 1, stride = 1,upscale_factor = 2):\n",
    "        super(Upsample_block, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor )\n",
    "        self.prelu = nn.PReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pixel_shuffle(x)\n",
    "        x = self.prelu(x)\n",
    "        return x\n",
    "\n",
    "class Genarator(nn.Module):\n",
    "    #im not going to add input parameters here because it would be really long, if any thing should change from default values, you have to chance it on the class\n",
    "    def __init__(self,num_res_blocks = 16, upsampling_factor = 4):\n",
    "        super(Genarator, self).__init__()\n",
    "        self.upsampling_factor = upsampling_factor\n",
    "        self.conv1 = convelutional_block()\n",
    "        reasuidual_layer_list =[Resedual_connection() for _ in range(num_res_blocks)]\n",
    "        self.residual_layers = nn.Sequential(*reasuidual_layer_list)\n",
    "        self.post_residual_convolution = Post_residual_convolution()\n",
    "        self.upsampling = nn.Sequential(\n",
    "            Upsample_block(upscale_factor=2),\n",
    "            Upsample_block(upscale_factor=2)\n",
    "        )\n",
    "        self.final_layer = nn.Conv2d(64, 3, 9, 1, 4)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        residual = x\n",
    "        x = self.residual_layers(x)\n",
    "        x = self.post_residual_convolution(x)\n",
    "        x += residual\n",
    "        x = self.upsampling(x)\n",
    "        x = self.final_layer(x)\n",
    "        x = self.tanh(x)\n",
    "        return x"
   ],
   "id": "10d6a98640baaa86"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "\n",
    "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            self._block(64, 64, stride=2),\n",
    "            self._block(64, 128, stride=1),\n",
    "            self._block(128, 128, stride=2),\n",
    "            self._block(128, 256, stride=1),\n",
    "            self._block(256, 256, stride=2),\n",
    "            self._block(256, 512, stride=1),\n",
    "            self._block(512, 512, stride=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512 * 6 * 6, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 1)\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, stride, 1),\n",
    "            nn.InstanceNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return self.classifier(x)"
   ],
   "id": "2bed6f4251136c03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class SRdataset(Dataset):\n",
    "    def __init__(self,High_resalution_paths,Low_resalution_paths,Scale = 4,crop_size = 96,is_traning =True):\n",
    "        super(SRdataset,self).__init__()\n",
    "\n",
    "        self.High_paths = High_resalution_paths\n",
    "        self.Low_paths = Low_resalution_paths\n",
    "        self.scale = Scale\n",
    "        self.crop_size = crop_size\n",
    "        self.is_traning = is_traning\n",
    "        self.path_and_image_pairs = self.create_image_path_pairs()\n",
    "        self.High_Resalution_image_transformations = A.Compose([A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]), ToTensorV2()])\n",
    "        self.Low_Resalution_image_transformations = A.Compose([A.Normalize(mean=[0, 0, 0], std=[1, 1, 1]), ToTensorV2()])\n",
    "\n",
    "\n",
    "    def create_image_path_pairs(self):\n",
    "\n",
    "        pairs = []\n",
    "\n",
    "        for high_path,low_path in zip(self.High_paths,self.Low_paths):\n",
    "\n",
    "            hr_file_names = sorted(os.listdir(high_path))\n",
    "            lr_file_names = sorted(os.listdir(low_path))\n",
    "\n",
    "            if len(hr_file_names) != len(lr_file_names):\n",
    "                raise RuntimeError(f\"Mismatched file counts in {high_path} ({len(hr_file_names)}) and {low_path} ({len(lr_file_names)})\")\n",
    "\n",
    "            dir_pairs_with_imges = list(zip(\n",
    "                                        [(high_path,hr_file_name) for hr_file_name in hr_file_names],\n",
    "                                        [(low_path,lr_file_name) for lr_file_name in lr_file_names])\n",
    "                                        )\n",
    "\n",
    "            pairs.extend(dir_pairs_with_imges)\n",
    "\n",
    "        return pairs\n",
    "\n",
    "    def load_image(self,path):\n",
    "        img = cv2.imread(path)\n",
    "        if img is None:\n",
    "            raise ValueError(f\"Could not Load the image of path : {path}\")\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        return  img.astype(np.float32)\n",
    "\n",
    "    def Transformation(self,high_resalution_image,Low_resalution_image):\n",
    "\n",
    "        if not self.is_traning:\n",
    "            high_resalution_Tensor = self.High_Resalution_image_transformations(image = high_resalution_image)[\"image\"]\n",
    "            Low_resalution_Tensor = self.Low_Resalution_image_transformations(image = Low_resalution_image)[\"image\"]\n",
    "\n",
    "            return Low_resalution_Tensor,high_resalution_Tensor\n",
    "\n",
    "        if self.is_traning:\n",
    "\n",
    "            h,w = high_resalution_image.shape[:2]\n",
    "            x = np.random.randint(0,w - self.crop_size +1)\n",
    "            y = np.random.randint(0,h - self.crop_size + 1)\n",
    "\n",
    "            low_res_crop_size = self.crop_size // self.scale\n",
    "            low_res_crop_x = x // self.scale\n",
    "            low_res_crop_y = y // self.scale\n",
    "\n",
    "            highres_crop = high_resalution_image[y:y+self.crop_size, x:x+self.crop_size,:]\n",
    "            lowres_crop = Low_resalution_image[low_res_crop_y:low_res_crop_y+low_res_crop_size, low_res_crop_x:low_res_crop_x+low_res_crop_size,:]\n",
    "\n",
    "            do_flip = np.random.random() < 0.5\n",
    "            if do_flip:\n",
    "                highres_crop = np.fliplr(highres_crop).copy()\n",
    "                lowres_crop = np.fliplr(lowres_crop).copy()\n",
    "\n",
    "            high_resalution_Tensor = self.High_Resalution_image_transformations(image=highres_crop)['image']\n",
    "            Low_resalution_Tensor = self.Low_Resalution_image_transformations(image=lowres_crop)['image']\n",
    "\n",
    "            return Low_resalution_Tensor, high_resalution_Tensor\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        (hr_path,hr_name),(lr_path,lr_name) = self.path_and_image_pairs[idx]\n",
    "\n",
    "        hr_path = os.path.join(hr_path, hr_name)\n",
    "        lr_path = os.path.join(lr_path, lr_name)\n",
    "\n",
    "        hr_image = self.load_image(hr_path)\n",
    "        lr_image = self.load_image(lr_path)\n",
    "\n",
    "        return self.Transformation(hr_image, lr_image) #return lower_res , Hig_res\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path_and_image_pairs)"
   ],
   "id": "a1f84f7ad417c9ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, device='cuda', scale_factor=1/12.75):\n",
    "        super(VGGLoss, self).__init__()\n",
    "        vgg = vgg19(weights=VGG19_Weights.DEFAULT).features[:36].eval().to(Device)\n",
    "        for param in vgg.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.vgg = vgg\n",
    "        self.scale_factor = scale_factor\n",
    "\n",
    "\n",
    "        self.register_buffer('mean', torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1))\n",
    "        self.register_buffer('std', torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1))\n",
    "\n",
    "    def forward(self, sr, hr):\n",
    "\n",
    "        sr = (sr + 1) / 2\n",
    "\n",
    "\n",
    "        # hr = torch.clamp(hr, 0, 1)\n",
    "\n",
    "        sr = (sr - self.mean) / self.std\n",
    "        hr = (hr - self.mean) / self.std\n",
    "\n",
    "\n",
    "        sr_features = self.vgg(sr)\n",
    "        hr_features = self.vgg(hr)\n",
    "\n",
    "        N, C, H, W = sr_features.size()\n",
    "\n",
    "\n",
    "        loss = torch.mean((sr_features - hr_features) ** 2) * self.scale_factor / (H * W)\n",
    "        return loss"
   ],
   "id": "540d9e2729436525"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class TrainingPhase(Enum):\n",
    "    PRETRAIN = \"pretrain\"\n",
    "    SRGAN = \"srgan\"\n",
    "\n",
    "\n",
    "class CheckpointHandler:\n",
    "    def __init__(self,primary_path,phase=TrainingPhase.PRETRAIN):\n",
    "        self.base_dir = Path(primary_path)\n",
    "        self.phase = phase\n",
    "\n",
    "        self.latest_dir = self.base_dir / phase.value / 'latest'\n",
    "        self.best_dir = self.base_dir / phase.value / 'best'\n",
    "        self.numbered_dir = self.base_dir / phase.value / 'numbered'\n",
    "\n",
    "        for dir_path in [self.latest_dir, self.best_dir, self.numbered_dir]:\n",
    "            dir_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        self.best_psnr = 0.0\n",
    "\n",
    "    def save_checkpoint(self, generator,g_optimizer=None,g_scheduler = None, discriminator=None,\n",
    "                        d_optimizer=None, d_scheduler = None,\n",
    "                       iteration=0, psnr=None, is_best=False):\n",
    "\n",
    "        if self.phase == TrainingPhase.PRETRAIN:\n",
    "            checkpoint = {\n",
    "                'iteration': iteration,\n",
    "                'generator_state': generator.state_dict(),\n",
    "                'g_optimizer_state': g_optimizer.state_dict() if g_optimizer else None,\n",
    "                'g_scheduler_state': g_scheduler .state_dict() if g_scheduler else None\n",
    "            }\n",
    "        else:\n",
    "            checkpoint = {\n",
    "                'iteration': iteration,\n",
    "                'generator_state': generator.state_dict(),\n",
    "                'discriminator_state': discriminator.state_dict() if discriminator else None,\n",
    "                'g_optimizer_state': g_optimizer.state_dict() if g_optimizer else None,\n",
    "                'd_optimizer_state': d_optimizer.state_dict() if d_optimizer else None,\n",
    "                'g_scheduler_state': g_scheduler .state_dict() if g_scheduler else None,\n",
    "                'd_scheduler_state': d_scheduler .state_dict() if d_scheduler else None\n",
    "            }\n",
    "\n",
    "        latest_path = self.latest_dir / 'latest_checkpoint.pt'\n",
    "        torch.save(checkpoint, latest_path)\n",
    "\n",
    "        if iteration % 50 == 0:\n",
    "            numbered_path = self.numbered_dir / f'checkpoint_{iteration}.pt'\n",
    "            torch.save(checkpoint, numbered_path)\n",
    "\n",
    "        if is_best and psnr is not None and psnr > self.best_psnr:\n",
    "            self.best_psnr = psnr\n",
    "            best_path = self.best_dir / 'best_model.pt'\n",
    "            torch.save(checkpoint, best_path)\n",
    "\n",
    "\n",
    "    def load_checkpoint(self, generator,g_optimizer=None,g_scheduler = None, discriminator=None,\n",
    "                        d_optimizer=None,d_scheduler = None,\n",
    "                       checkpoint_type='latest'):\n",
    "\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "        if checkpoint_type == 'latest':\n",
    "            checkpoint_path = self.latest_dir / 'latest_checkpoint.pt'\n",
    "        elif checkpoint_type == 'best':\n",
    "            checkpoint_path = self.best_dir / 'best_model.pt'\n",
    "        else:\n",
    "            checkpoint_path = self.numbered_dir / f'checkpoint_{checkpoint_type}.pt'\n",
    "\n",
    "        if not checkpoint_path.exists():\n",
    "            print(f\"No checkpoint found at {checkpoint_path}\")\n",
    "            return 0\n",
    "\n",
    "        checkpoint = torch.load(checkpoint_path, map_location=device)\n",
    "        generator.to(device)\n",
    "        generator.load_state_dict(checkpoint['generator_state'])\n",
    "\n",
    "        if g_scheduler and 'g_scheduler_state' in checkpoint:\n",
    "            g_scheduler.load_state_dict(checkpoint['g_scheduler_state'])\n",
    "\n",
    "        if g_optimizer and 'g_optimizer_state' in checkpoint:\n",
    "            g_optimizer.load_state_dict(checkpoint['g_optimizer_state'])\n",
    "\n",
    "        if self.phase == TrainingPhase.SRGAN:\n",
    "            if discriminator and 'discriminator_state' in checkpoint:\n",
    "                discriminator.to(device)\n",
    "                discriminator.load_state_dict(checkpoint['discriminator_state'])\n",
    "\n",
    "            if d_optimizer and 'd_optimizer_state' in checkpoint:\n",
    "                d_optimizer.load_state_dict(checkpoint['d_optimizer_state'])\n",
    "\n",
    "            if d_scheduler and 'd_scheduler_state' in checkpoint:\n",
    "                d_scheduler.load_state_dict(checkpoint['d_scheduler_state'])\n",
    "\n",
    "\n",
    "        return checkpoint['iteration']\n",
    "\n",
    "    def clean_old_checkpoints(self, keep_last_n=3):\n",
    "        checkpoint_files = sorted(list(self.numbered_dir.glob('checkpoint_*.pt')))\n",
    "        for checkpoint_file in checkpoint_files[:-keep_last_n]:\n",
    "            checkpoint_file.unlink()\n",
    "\n",
    "    def ischeackpoint(self):\n",
    "        if os.path.exists(self.latest_dir) and os.path.isdir(self.latest_dir) and os.listdir(self.latest_dir):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n"
   ],
   "id": "c72ea86b48885e1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class LossCheckpointHandler:\n",
    "    def __init__(self, primary_path):\n",
    "        self.base_dir = Path(primary_path)\n",
    "        self.loss_dir = self.base_dir / 'losses'\n",
    "        self.loss_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.losses = []\n",
    "\n",
    "    def append_loss(self, new_loss):\n",
    "        if torch.is_tensor(new_loss):\n",
    "            new_loss = new_loss.cpu().detach().numpy()\n",
    "        self.losses.append(new_loss)\n",
    "\n",
    "    def save_checkpoint(self, iteration):\n",
    "        checkpoint = {\n",
    "            'iteration': iteration,\n",
    "            'loss_history': self.losses\n",
    "        }\n",
    "        torch.save(checkpoint, self.loss_dir / 'loss_history.pt')\n",
    "\n",
    "    def load_checkpoint(self):\n",
    "        path = self.loss_dir / 'loss_history.pt'\n",
    "        if path.exists():\n",
    "            checkpoint = torch.load(path)\n",
    "            self.losses = checkpoint['loss_history']\n",
    "            return checkpoint['iteration'], self.losses\n",
    "        return 0 ,[]"
   ],
   "id": "8f478ed3eb308c3f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "class ImageEvaluationMetrics:\n",
    "    def __init__(self, device):\n",
    "        self.device = device\n",
    "        self.mse_criterion = nn.MSELoss().to(device)\n",
    "        self.lpips_criterion = lpips.LPIPS(net='alex').to(device)\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "\n",
    "    def load_and_prepare_image(self, image_path):\n",
    "\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_tensor = self.transform(img).unsqueeze(0).to(self.device)\n",
    "        return img_tensor\n",
    "\n",
    "    def prepare_images(self, sr, hr):\n",
    "\n",
    "        sr_01 = torch.clamp((sr + 1) / 2, 0, 1)\n",
    "        hr_01 = torch.clamp((hr + 1) / 2, 0, 1)\n",
    "\n",
    "\n",
    "        normalize = transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        sr_lpips = normalize(sr_01)\n",
    "        hr_lpips = normalize(hr_01)\n",
    "\n",
    "        return sr_01, hr_01, sr_lpips, hr_lpips\n",
    "\n",
    "    def calculate_ssim(self, sr, hr, window_size=11):\n",
    "\n",
    "        C1 = (0.01 * 1) ** 2\n",
    "        C2 = (0.03 * 1) ** 2\n",
    "\n",
    "        mu1 = F.avg_pool2d(sr, window_size, stride=1, padding=window_size//2)\n",
    "        mu2 = F.avg_pool2d(hr, window_size, stride=1, padding=window_size//2)\n",
    "\n",
    "        mu1_sq = mu1.pow(2)\n",
    "        mu2_sq = mu2.pow(2)\n",
    "        mu1_mu2 = mu1 * mu2\n",
    "\n",
    "        sigma1_sq = F.avg_pool2d(sr * sr, window_size, stride=1, padding=window_size//2) - mu1_sq\n",
    "        sigma2_sq = F.avg_pool2d(hr * hr, window_size, stride=1, padding=window_size//2) - mu2_sq\n",
    "        sigma12 = F.avg_pool2d(sr * hr, window_size, stride=1, padding=window_size//2) - mu1_mu2\n",
    "\n",
    "        ssim = ((2 * mu1_mu2 + C1) * (2 * sigma12 + C2)) / ((mu1_sq + mu2_sq + C1) * (sigma1_sq + sigma2_sq + C2))\n",
    "        return ssim.mean()\n",
    "\n",
    "    def evaluate_images(self, generator, lr_path, hr_path):\n",
    "\n",
    "        generator.eval()\n",
    "        metrics = {}\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            lr = self.load_and_prepare_image(lr_path)\n",
    "            hr = self.load_and_prepare_image(hr_path)\n",
    "\n",
    "            sr = generator(lr)\n",
    "\n",
    "            sr_01, hr_01, sr_lpips, hr_lpips = self.prepare_images(sr, hr)\n",
    "\n",
    "            mse = self.mse_criterion(sr_01, hr_01).item()\n",
    "            psnr = -10 * torch.log10(torch.tensor(mse + 1e-8))\n",
    "            ssim = self.calculate_ssim(sr_01, hr_01)\n",
    "            lpips_value = self.lpips_criterion(sr_lpips, hr_lpips).mean()\n",
    "\n",
    "            metrics = {\n",
    "                'mse': mse,\n",
    "                'psnr': psnr.item(),\n",
    "                'ssim': ssim.item(),\n",
    "                'lpips': lpips_value.item()\n",
    "            }\n",
    "\n",
    "        generator.train()\n",
    "        return metrics\n",
    "\n",
    "    def evaluate_directory(self, generator, lr_dir, hr_dir):\n",
    "\n",
    "        total_metrics = {'psnr': 0, 'ssim': 0, 'mse': 0, 'lpips': 0}\n",
    "        n_samples = 0\n",
    "\n",
    "        lr_files = sorted([f for f in Path(lr_dir).glob('*.png')])\n",
    "        hr_files = sorted([f for f in Path(hr_dir).glob('*.png')])\n",
    "\n",
    "        for lr_path, hr_path in zip(lr_files, hr_files):\n",
    "            metrics = self.evaluate_images(generator, lr_path, hr_path)\n",
    "\n",
    "            for k, v in metrics.items():\n",
    "                total_metrics[k] += v\n",
    "            n_samples += 1\n",
    "\n",
    "        avg_metrics = {k: v/n_samples for k, v in total_metrics.items()}\n",
    "        return avg_metrics"
   ],
   "id": "d8d0e8dfd086f96a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def gradient_penalty(critc,real,fake,device):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    epsilon = torch.rand((BATCH_SIZE, 1, 1, 1)).to(device)\n",
    "    interpolated_images = real * epsilon + fake * (1 - epsilon)\n",
    "    interpolated_images.requires_grad = True\n",
    "    mixed_scores = critc(interpolated_images)\n",
    "    gradient = autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty,gradient_norm"
   ],
   "id": "d027a8a5a55c57cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def show_model_results(model, image_path):\n",
    "\n",
    "    import torch\n",
    "    from PIL import Image\n",
    "    import torchvision.transforms as transforms\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    def deprocess_image(image):\n",
    "\n",
    "        image = image / 2 + 0.5\n",
    "        image = np.clip(image * 255, 0, 255)\n",
    "        return image.astype(np.uint8)\n",
    "\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "    ])\n",
    "\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    input_tensor = transform(img).unsqueeze(0).to('cuda')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "\n",
    "    output = deprocess_image(output.cpu().squeeze(0).permute(1, 2, 0).numpy())\n",
    "    model.train()\n",
    "    Image.fromarray(output).save('output.png', quality=100, subsampling=0)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(output)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ],
   "id": "d80fa4eb95b2a92c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "Train_High_resalution_image_paths = [\"/kaggle/input/flickr2k/Flickr2K/Flickr2K_HR\",\"/kaggle/input/div2k-dataset-for-super-resolution/Dataset/DIV2K_train_HR\",\"/kaggle/input/srgan-faces-4x/Faces_with_4x_downsamples/high_resolution\",\"/kaggle/input/urban100/Urban 100/X4 Urban100/X4/HIGH x4 URban100\"]\n",
    "Train_Low_resalution_image_paths = [\"/kaggle/input/flickr2k/Flickr2K/Flickr2K_LR_bicubic/X4\",\"/kaggle/input/div2k-dataset-for-super-resolution/Dataset/DIV2K_train_LR_bicubic_X4/X4\",\"/kaggle/input/srgan-faces-4x/Faces_with_4x_downsamples/low_resolution\",\"/kaggle/input/urban100/Urban 100/X4 Urban100/X4/LOW x4 URban100\"]\n",
    "\n",
    "Train_dataset = SRdataset(Train_High_resalution_image_paths,Train_Low_resalution_image_paths)\n",
    "Train_dataloader = DataLoader(Train_dataset,batch_size=256,shuffle=True,num_workers=4,pin_memory=True,drop_last=True)\n",
    "\n",
    "valid_High_resalution_image_paths = [\"/kaggle/input/div2k-dataset-for-super-resolution/Dataset/DIV2K_valid_HR\"]\n",
    "valid_low_resalution_image_paths = [\"/kaggle/input/div2k-dataset-for-super-resolution/Dataset/DIV2K_valid_LR_bicubic_X4/X4\"]\n",
    "\n",
    "valid_dataset = SRdataset(valid_High_resalution_image_paths,valid_low_resalution_image_paths)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=16,shuffle=True,num_workers=4,pin_memory=True,drop_last=True)\n"
   ],
   "id": "41f3cc31c5fdf789"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "learning_rate = 1e-4\n",
    "Generator_model = Genarator()\n",
    "Genarator_optimizer = torch.optim.Adam(Generator_model.parameters(),lr = learning_rate, betas=(0.9, 0.999))\n",
    "g_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(Genarator_optimizer,mode='min',factor=0.5,patience=5000,verbose=True,min_lr=1e-6)\n",
    "loss_function = VGGLoss() #data,lables\n",
    "mseloss = nn.MSELoss()\n",
    "g_CheckpointHandler = CheckpointHandler(\"/kaggle/working/\",TrainingPhase.PRETRAIN)\n",
    "LossHandler = LossCheckpointHandler(\"/kaggle/working/\")"
   ],
   "id": "5bf19c9d695a81ca"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def Full_model_gd_norm(model):\n",
    "    total_norm = 0\n",
    "    for p in model.parameters():\n",
    "        if p.grad is not None:\n",
    "            param_norm = p.grad.data.norm(2)\n",
    "            total_norm += param_norm.item() ** 2\n",
    "    total_norm = total_norm ** 0.5\n",
    "    return total_norm"
   ],
   "id": "691e36773731d4bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "current_iteration = 0\n",
    "max_iterations = 800\n",
    "Generator_model.to(Device)\n",
    "loss_function.to(Device)\n",
    "losses = []\n",
    "if g_CheckpointHandler.ischeackpoint():\n",
    "    current_iteration = g_CheckpointHandler.load_checkpoint(Generator_model,Genarator_optimizer,g_scheduler) +1\n",
    "    loss_itration,losses = LossHandler.load_checkpoint()\n",
    "    # for param_group in Genarator_optimizer.param_groups:\n",
    "    #     param_group['lr'] = 1e-3\n",
    "\n",
    "for epoc in range(current_iteration,max_iterations):\n",
    "    batch_loss = []\n",
    "    t1 = time.time()\n",
    "    for data ,lables in Train_dataloader:\n",
    "\n",
    "        data = data.to(Device)\n",
    "        lables = lables.to(Device)\n",
    "\n",
    "        predict = Generator_model(data)\n",
    "\n",
    "        loss = mseloss(predict,lables) + 10*loss_function(predict,lables)\n",
    "\n",
    "        batch_loss.append(loss.item())\n",
    "\n",
    "        Genarator_optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        Genarator_optimizer.step()\n",
    "    mean_batch_loss = np.mean(batch_loss)\n",
    "    # g_scheduler.step(mean_batch_loss)\n",
    "    losses.append(mean_batch_loss)\n",
    "    LossHandler.append_loss(mean_batch_loss)\n",
    "    t2 = time.time()\n",
    "\n",
    "    if (epoc + 1) % 10 == 0:\n",
    "        g_CheckpointHandler.save_checkpoint(Generator_model,Genarator_optimizer,g_scheduler,iteration = epoc)\n",
    "        LossHandler.save_checkpoint(epoc)\n",
    "\n",
    "    sys.stdout.write(f\"\\r{epoc + 1} / {max_iterations} epocs ,time:{t2-t1} ,LR: {Genarator_optimizer.param_groups[0]['lr']} ,Loss : {mean_batch_loss} , grad :{Full_model_gd_norm(Generator_model)}\")\n",
    "    sys.stdout.flush()\n",
    "\n"
   ],
   "id": "82c2141b10066960"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "show_model_results(Generator_model.to(Device),\"/kaggle/input/div2k-dataset-for-super-resolution/Dataset/DIV2K_valid_LR_bicubic_X4/X4/0850x4.png\")",
   "id": "dbc3a0e21444a867"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "learning_rate = 1e-4\n",
    "Generator_model = Genarator()\n",
    "Critic_model = Critic()\n",
    "Genarator_optimizer = torch.optim.Adam(Generator_model.parameters(),lr = learning_rate, betas=(0, 0.9))\n",
    "Critic_optimizer = torch.optim.Adam(Critic_model.parameters(),lr = learning_rate, betas=(0, 0.9))\n",
    "g_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(Genarator_optimizer,mode='min',factor=0.5,patience=5000,verbose=True,min_lr=1e-6)\n",
    "c_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(Critic_optimizer,mode='min',factor=0.5,patience=5000,verbose=True,min_lr=1e-6)\n",
    "loss_function = VGGLoss() #data,lables\n",
    "mseLoss = nn.MSELoss()\n",
    "srgan_CheckpointHandler = CheckpointHandler(\"/kaggle/working/\",TrainingPhase.SRGAN)\n",
    "LossHandlerSrgan = LossCheckpointHandler(\"/kaggle/working/SRGANLoss\")\n"
   ],
   "id": "12b3660139d76df9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "current_iteration = 0\n",
    "max_iterations = 100\n",
    "Generator_model.to(Device)\n",
    "Critic_model.to(Device)\n",
    "loss_function.to(Device)\n",
    "mseLoss.to(Device)\n",
    "if srgan_CheckpointHandler.ischeackpoint():\n",
    "    current_iteration = srgan_CheckpointHandler.load_checkpoint(Generator_model,Genarator_optimizer,g_scheduler,Critic_model,Critic_optimizer,c_scheduler) +1\n",
    "    loss_itration,losses = LossHandlerSrgan.load_checkpoint()\n",
    "\n",
    "Ganlosses_Generator = []\n",
    "Ganlosses_Critic = []\n",
    "Valid_Ganlosses_Generator = []\n",
    "Valid_Ganlosses_Critic = []\n",
    "ncritic_epoc = 5\n",
    "for epoc in range(current_iteration,max_iterations):\n",
    "    Gan_batch_G = []\n",
    "    Gan_batch_C = []\n",
    "    critic_real_loss_batch = []\n",
    "    lamda = 10\n",
    "    critic_data = iter(Train_dataloader)\n",
    "    t1 = time.time()\n",
    "    for data ,lables in Train_dataloader:\n",
    "\n",
    "        critic_nepoc_loss = []\n",
    "        critic_nepoc_loss_real = []\n",
    "        for _ in range(ncritic_epoc):\n",
    "            try:\n",
    "                crtic_data,critc_labels = next(critic_data)\n",
    "\n",
    "            except StopIteration:\n",
    "                critic_data = iter(Train_dataloader)\n",
    "                crtic_data,critc_labels = next(critic_data)\n",
    "\n",
    "            crtic_data = crtic_data.to(Device)\n",
    "            critc_labels = critc_labels.to(Device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = Generator_model(crtic_data)\n",
    "            fake_score = Critic_model(fake)\n",
    "            real_score = Critic_model(critc_labels)\n",
    "            grad_penalty,gradient_norm = gradient_penalty(Critic_model,critc_labels,fake,Device)\n",
    "            real_critc_loss = -(torch.mean(real_score) - torch.mean(fake_score))\n",
    "            critic_loss = real_critc_loss + lamda * grad_penalty\n",
    "            critic_nepoc_loss_real.append(real_critc_loss.item())\n",
    "            critic_nepoc_loss.append(critic_loss.item())\n",
    "            Critic_optimizer.zero_grad()\n",
    "            critic_loss.backward()\n",
    "            Critic_optimizer.step()\n",
    "\n",
    "        data = data.to(Device)\n",
    "        lables = lables.to(Device)\n",
    "        Gan_batch_C.append(np.mean(critic_nepoc_loss))\n",
    "        critic_real_loss_batch.append(np.mean(critic_nepoc_loss_real))\n",
    "        fake = Generator_model(data)\n",
    "        fake_score = Critic_model(fake)\n",
    "        generator_loss = -1e-2 * torch.mean(fake_score) + 2.0 *mseLoss(fake,lables) + 10.0 * loss_function(fake,lables)\n",
    "        Genarator_optimizer.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        Genarator_optimizer.step()\n",
    "        Gan_batch_G.append(generator_loss.item())\n",
    "\n",
    "    mean_real_critc_loss_full = np.mean(critic_real_loss_batch)\n",
    "    mean_batch_loss_G = np.mean(Gan_batch_G)\n",
    "    mean_batch_loss_C = np.mean(Gan_batch_C)\n",
    "    Ganlosses_Generator.append(mean_batch_loss_G)\n",
    "    Ganlosses_Critic.append(mean_batch_loss_C)\n",
    "    LossHandlerSrgan.append_loss([mean_batch_loss_G,mean_batch_loss_C])\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     valid_Gan_batch_G = []\n",
    "    #     valid_Gan_batch_C = []\n",
    "    #     for data ,lables in valid_dataloader:\n",
    "    #         data = data.to(Device)\n",
    "    #         lables = lables.to(Device)\n",
    "    #         fake = Generator_model(data)\n",
    "    #         fake_score = Critic_model(fake)\n",
    "    #         real_score = Critic_model(lables)\n",
    "    #         critic_loss = -(torch.mean(real_score) - torch.mean(fake_score))\n",
    "    #         fake = Generator_model(data)\n",
    "    #         fake_score = Critic_model(fake)\n",
    "    #         generator_loss = -1e-3 * torch.mean(fake_score) + mseLoss(fake,lables) + 10 * loss_function(fake,lables)\n",
    "    #         valid_Gan_batch_G.append(generator_loss.item())\n",
    "    #         valid_Gan_batch_C.append(critic_loss.item())\n",
    "    #     Valid_Ganlosses_Generator.append(np.mean(valid_Gan_batch_G))\n",
    "    #     Valid_Ganlosses_Critic.append(np.mean(valid_Gan_batch_C))\n",
    "\n",
    "    t2 = time.time()\n",
    "    if (epoc + 1) % 10 == 0:\n",
    "        srgan_CheckpointHandler.save_checkpoint(Generator_model,Genarator_optimizer,g_scheduler,Critic_model,Critic_optimizer,c_scheduler,iteration = epoc)\n",
    "        LossHandlerSrgan.save_checkpoint(epoc)\n",
    "    sys.stdout.write(f\"\\r{epoc + 1}/{max_iterations}epocs,time:{t2-t1},GLoss:{mean_batch_loss_G},CLoss:{mean_batch_loss_C},grad:{Full_model_gd_norm(Generator_model)},cgrad:{Full_model_gd_norm(Critic_model)},RCLoss {mean_real_critc_loss_full} \")\n",
    "    sys.stdout.flush()\n",
    "\n"
   ],
   "id": "7855ba6e8074fda2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "show_model_results(Generator_model.to(Device),\"/kaggle/input/srgan-faces-4x/Faces_with_4x_downsamples/low_resolution/00403.png\")"
   ],
   "id": "b3be97b9cbae4273"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
